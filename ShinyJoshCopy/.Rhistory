sentence <- gsub("[^[:alnum:]///' ]", "", sentence)
sentence <- gsub('[[:punct:]]', '', sentence)
sentence <- gsub('[[:cntrl:]]', '', sentence)
sentence <- gsub('\\d+', '', sentence)
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df <- data.frame(score=scores)
return(scores.df)
}
pos.words <- scan('positive-words.txt', what='character', comment.char=';')
pos.words <- scan('../data/positive-words.txt', what='character', comment.char=';')
neg.words <- scan('../data/negative-words.txt', what='character', comment.char=';')
d$score <- score.sentiment(d$word, pos.words, neg.words, .progress="text")
d$sentiment <- rep(0)
d$sentiment <- ifelse(d$score>=1, "Positive", d$sentiment)
d$sentiment <- ifelse(d$score==0, "Neutral", d$sentiment)
d$sentiment <- ifelse(d$score<=-1, "Negative", d$sentiment)
View(d$sentiment)
View(d)
subset(d[1:50,])%>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
library(ggplot2)
subset(d[1:50,])%>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
pos.words <- scan('../data/positive-words.txt', what='character', comment.char=';')
neg.words <- scan('../data/negative-words.txt', what='character', comment.char=';')
combined<-readRDS("../data/prof_combined_sentiment.rds")
corpus <- Corpus(VectorSource(combined$review_text))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
tdm <- TermDocumentMatrix(docs)
options(mc.cores=1)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
txtTdmBi <- TermDocumentMatrix(docs, control = list(tokenize = BigramTokenizer))
m = as.matrix(txtTdmBi)
v = sort(rowSums(m),decreasing=TRUE)
d = data.frame(word = names(v),freq=v)
d$score <- score.sentiment(d$word, pos.words, neg.words, .progress="text")
d$sentiment <- rep(0)
d$sentiment <- ifelse(d$score>=1, "Positive", d$sentiment)
d$sentiment <- ifelse(d$score==0, "Neutral", d$sentiment)
d$sentiment <- ifelse(d$score<=-1, "Negative", d$sentiment)
subset(d[1:50,])%>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, c("assignments", "every" "computer", "cs", "professor", "dont", "prof", "first"))
corpus <- Corpus(VectorSource(combined$workload_text))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, c("assignments", "every", "computer", "cs", "professor", "dont", "prof", "first"))
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
tdm <- TermDocumentMatrix(docs)
options(mc.cores=1)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
txtTdmBi <- TermDocumentMatrix(docs, control = list(tokenize = BigramTokenizer))
m = as.matrix(txtTdmBi)
v = sort(rowSums(m),decreasing=TRUE)
d = data.frame(word = names(v),freq=v)
d$score <- score.sentiment(d$word, pos.words, neg.words, .progress="text")
d$sentiment <- rep(0)
d$sentiment <- ifelse(d$score>=1, "Positive", d$sentiment)
d$sentiment <- ifelse(d$score==0, "Neutral", d$sentiment)
d$sentiment <- ifelse(d$score<=-1, "Negative", d$sentiment)
subset(d[1:50,])%>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
corpus <- Corpus(VectorSource(combined$workload_text))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, c("take", "assignments", "every", "computer", "cs", "professor", "dont", "prof", "first"))
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
tdm <- TermDocumentMatrix(docs)
options(mc.cores=1)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
txtTdmBi <- TermDocumentMatrix(docs, control = list(tokenize = BigramTokenizer))
m = as.matrix(txtTdmBi)
v = sort(rowSums(m),decreasing=TRUE)
d = data.frame(word = names(v),freq=v)
d$score <- score.sentiment(d$word, pos.words, neg.words, .progress="text")
d$sentiment <- rep(0)
d$sentiment <- ifelse(d$score>=1, "Positive", d$sentiment)
d$sentiment <- ifelse(d$score==0, "Neutral", d$sentiment)
d$sentiment <- ifelse(d$score<=-1, "Negative", d$sentiment)
subset(d[1:50,])%>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
corpus <- Corpus(VectorSource(combined$workload_text))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, c("take", "assignments", "every", "computer", "cs", "professor", "dont", "prof", "first", "programming"))
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
tdm <- TermDocumentMatrix(docs)
options(mc.cores=1)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
options(mc.cores=1)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
txtTdmBi <- TermDocumentMatrix(docs, control = list(tokenize = BigramTokenizer))
m = as.matrix(txtTdmBi)
v = sort(rowSums(m),decreasing=TRUE)
d = data.frame(word = names(v),freq=v)
d$score <- score.sentiment(d$word, pos.words, neg.words, .progress="text")
d$sentiment <- rep(0)
d$sentiment <- ifelse(d$score>=1, "Positive", d$sentiment)
d$sentiment <- ifelse(d$score==0, "Neutral", d$sentiment)
d$sentiment <- ifelse(d$score<=-1, "Negative", d$sentiment)
subset(d[1:50,])%>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
corpus <- Corpus(VectorSource(combined$workload_text))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, c("take", "assignments", "every", "computer", "cs", "professor", "dont", "prof", "first", "programming"))
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
tdm <- TermDocumentMatrix(docs)
m = as.matrix(tdm)
v = sort(rowSums(m),decreasing=TRUE)
d = data.frame(word = names(v),freq=v)
d$score <- score.sentiment(d$word, pos.words, neg.words, .progress="text")
d$sentiment <- rep(0)
d$sentiment <- ifelse(d$score>=1, "Positive", d$sentiment)
d$sentiment <- ifelse(d$score==0, "Neutral", d$sentiment)
d$sentiment <- ifelse(d$score<=-1, "Negative", d$sentiment)
subset(d[1:50,])%>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
install.packages("~/Downloads/sentiment_0.1.tar", repos = NULL)
source("classify_emotion.R")
source("classify_polarity.R")
source("create_matrix.R")
class_emo = classify_emotion(docs, algorithm="bayes", prior=1.0)
class_emo = classify_emotion(combined$review_text, algorithm="bayes", prior=1.0)
emotion = class_emo[,7]
# substitute NA's by "unknown"
emotion[is.na(emotion)] = "unknown"
# classify polarity
class_pol = classify_polarity(combined$review_text, algorithm="bayes")
# get polarity best fit
class_pol = classify_polarity(combined$review_text, algorithm="bayes")
source("classify_polarity.R")
class_pol = classify_polarity(combined$review_text, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text=some_txt, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = data.frame(text=combined$review_text, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
head(sent_df)
View(sent_df)
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = some_txt[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = combined$review_text[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords("english"))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Starbucks\n(classification by emotion)",
plot.title = theme_text(size=12))
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets"),
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets")
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="number of tweets")
source("classify_emotion.R")
source("classify_polarity.R")
source("create_matrix.R")
# classify emotion
class_emo = classify_emotion(combined$workload_text, algorithm="bayes", prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# substitute NA's by "unknown"
emotion[is.na(emotion)] = "unknown"
# classify polarity
class_pol = classify_polarity(combined$review_text, algorithm="bayes")
# get polarity best fit
polarity = class_pol[,4]
# data frame with results
sent_df = data.frame(text=combined$review_text, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets")
# plot distribution of polarity
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette="RdGy") +
labs(x="polarity categories", y="number of tweets")
class_emo = classify_emotion(combined$workload_text, algorithm="bayes", prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# substitute NA's by "unknown"
emotion[is.na(emotion)] = "unknown"
# classify polarity
class_pol = classify_polarity(combined$workload_text, algorithm="bayes")
# get polarity best fit
polarity = class_pol[,4]
# data frame with results
sent_df = data.frame(text=combined$workload_text, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets")
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = some_txt[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = ombined$workload_text[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = combined$workload_text[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords("english"))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets")
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = combined$workload_text[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords("english"))
emo.docs = removeWords(emo.docs, c("group", "final."))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep("", nemo)
for (i in 1:nemo)
{
tmp = combined$workload_text[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse=" ")
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords("english"))
emo.docs = removeWords(emo.docs, c("group", "final.", "final", "disgusting"))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = emos
# comparison word cloud
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(3,.5), random.order = FALSE, title.size = 1.5)
comparison.cloud(tdm, colors = brewer.pal(nemo, "Dark2"),
scale = c(2,.5), random.order = FALSE, title.size = 1.5)
library('dygraphs')
prof<-readRDS("www/prof_combined_sentiment.rds")
getwd()
setwd("../ShinyJoshCopy/")
prof<-readRDS("www/prof_combined_sentiment.rds")
View(prof)
pos.words <- scan('../data/positive-words.txt', what='character', comment.char=';')
neg.words <- scan('../data/negative-words.txt', what='character', comment.char=';')
combined<-readRDS("../data/prof_combined_sentiment.rds")
corpus <- Corpus(VectorSource(combined$review_text))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
tdm <- TermDocumentMatrix(docs)
options(mc.cores=1)
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
txtTdmBi <- TermDocumentMatrix(docs, control = list(tokenize = BigramTokenizer))
m = as.matrix(txtTdmBi)
v = sort(rowSums(m),decreasing=TRUE)
d = data.frame(word = names(v),freq=v)
d$score <- score.sentiment(d$word, pos.words, neg.words, .progress="text")
d$sentiment <- rep(0)
d$sentiment <- ifelse(d$score>=1, "Positive", d$sentiment)
d$sentiment <- ifelse(d$score==0, "Neutral", d$sentiment)
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none') {
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence <- gsub("&amp", "", sentence)
sentence <- gsub("[^[:alnum:]///' ]", "", sentence)
sentence <- gsub('[[:punct:]]', '', sentence)
sentence <- gsub('[[:cntrl:]]', '', sentence)
sentence <- gsub('\\d+', '', sentence)
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df <- data.frame(score=scores)
return(scores.df)
}
d$score <- score.sentiment(d$word, pos.words, neg.words, .progress="text")
d$sentiment <- rep(0)
d$sentiment <- ifelse(d$score>=1, "Positive", d$sentiment)
d$sentiment <- ifelse(d$score==0, "Neutral", d$sentiment)
d$sentiment <- ifelse(d$score<=-1, "Negative", d$sentiment)
subset(d[1:50,])%>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
summary(d)
pos.words <- scan('../data/positive-words.txt', what='character', comment.char=';')
neg.words <- scan('../data/negative-words.txt', what='character', comment.char=';')
combined<-readRDS("../data/prof_combined_sentiment.rds")
corpus <- Corpus(VectorSource(combined$workload_text))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
pos.words <- scan('../data/positive-words.txt', what='character', comment.char=';')
neg.words <- scan('../data/negative-words.txt', what='character', comment.char=';')
combined<-readRDS("../data/prof_combined_sentiment.rds")
corpus <- Corpus(VectorSource(combined$review_text))
docs <- tm_map(corpus, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, c("take", "assignments", "every", "computer", "cs", "professor", "dont", "prof", "first", "programming"))
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
tdm <- TermDocumentMatrix(docs)
d$score <- score.sentiment(docs, pos.words, neg.words, .progress="text")
d <- score.sentiment(docs, pos.words, neg.words, .progress="text")
VIew(d)
View(d)
shiny::runApp()
install.packages("shinydashboard")
shiny::runApp()
View(prof)
min(prof$created)
max(prof$created)
library(xts)
datetimes <- seq.POSIXt(as.POSIXct("2000-01-01", tz="GMT"), as.POSIXct("2015-01-22", tz="GMT"), by="1 day")
View(datetimes)
?xtx
?xts
series <- xts(d3$review_score, order.by = datetimes, tz="GMT")
d3<-Data()[[3]]
Data<-reactive({
#browser()
profData<-prof[prof$profName==input$profName,]
profDocs<-docs[prof$profName==input$profName]
txtTdmBi <- as.matrix(TermDocumentMatrix(profDocs, control = list(tokenize = BigramTokenizer)))
v = sort(rowSums(txtTdmBi),decreasing=TRUE)
d = data.frame(word = names(v),freq=v)
d<-d[!d$word%in%
c('final','midterm','finals','midterms','assignment','assignments','problem','problems'),]
if(nrow(d)>=30) d2<-d[1:30,]
else d2<-d
d2$score <- score.sentiment(d2$word, pos.words, neg.words, .progress="text")
d2$sentiment <- rep(0)
d2$sentiment <- ifelse(d2$score>=1, "Positive", d2$sentiment)
d2$sentiment <- ifelse(d2$score==0, "Neutral", d2$sentiment)
d2$sentiment <- ifelse(d2$score<=-1, "Negative", d2$sentiment)
d2$sentiment<-factor(d2$sentiment,levels=c('Positive','Neutral','Negative'))
d3 = data.frame(date = profData$created, score = profData$review_score)
return(list(profData,d2, d3))
})
d3<-Data()[[3]]
profData<-prof[prof$first_name=="Gail" && prof$last_name=="Kaiser",]
View(profData)
profData<-prof[prof$first_name=="Gail",]
View(profData)
d3 <- data.frame(date = profData$created, score = profData$review_score)
View(d3)
datetimes <- seq.POSIXt(as.POSIXct("2000-01-01", tz="GMT"), as.POSIXct("2015-01-22", tz="GMT"), by="1 day")
series <- xts(d3$review_score, order.by = datetimes, tz="GMT")
VIew(series)
View(series)
series[series$row.names=="2000-01-01"]
series[!is.na(series)]
series[!is.na(series),]
series[is.na(series),]
d3$review_score
series <- xts(d3$score, order.by = datetimes, tz="GMT")
d4<-data.frame(date = datetimes, score = integer())
d4<-data.frame(date = datetimes)
series <- xts(d3$score, order.by = d3$date, tz="GMT")
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
View(prof)
View(profData)
View(profData$nugget)
profData$nugget[1]
profData[1,]$nugget
prof$nugget
prof$nugget[1]
prof$nugget[1] == "None"
shiny::runApp()
shiny::runApp()
