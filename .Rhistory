save(my_oauth, file = "my_oauth.Rdata")
load("my_oauth.Rdata")
filterStream("tweets_hw1.json", track = c("Hillary Clinton","Bernie Sanders","Jeb Bush", "Marco Rubio", "Ted Cruz", "Donald Trump", "John Kasich", "Ben Carson", "Chris Christie","Carly Fiorina","Hillaryclinton","Jebbush","Berniesanders","Marcorubio","Chrischristie","Bencarson","Johnkasich", "Donaldtrump","Tedcruz","Carlyfiorina"), timeout = 1800, oauth = my_oauth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "bTJuvaRfO4aXxpPduFxlnoZH9"
consumerSecret <- "9MpvVaitTALxtPkWZdePg3wjGlwro7LsQHb0zmzDxQy9Y4FLdp"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret, requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
load("my_oauth.Rdata")
filterStream("tweets_hw1.json", track = c("Hillary Clinton","Bernie Sanders","Jeb Bush", "Marco Rubio", "Ted Cruz", "Donald Trump", "John Kasich", "Ben Carson", "Chris Christie","Carly Fiorina","Hillaryclinton","Jebbush","Berniesanders","Marcorubio","Chrischristie","Bencarson","Johnkasich", "Donaldtrump","Tedcruz","Carlyfiorina"), timeout = 1800, oauth = my_oauth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "rMaJgpDHD1mA3w0qZOMXxdNTR"
consumerSecret <- "VgQBsi00vc8VKBiKxvC0QtPEsDnTXkWA7KjvU9i0m0k9eCba6j"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret, requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
load("my_oauth.Rdata")
filterStream("tweets_hw1.json", track = c("Hillary Clinton","Bernie Sanders","Jeb Bush", "Marco Rubio", "Ted Cruz", "Donald Trump", "John Kasich", "Ben Carson", "Chris Christie","Carly Fiorina","Hillaryclinton","Jebbush","Berniesanders","Marcorubio","Chrischristie","Bencarson","Johnkasich", "Donaldtrump","Tedcruz","Carlyfiorina"), timeout = 1800, oauth = my_oauth)
library(streamR)
rm(list=ls())
library(streamR)
library(ROAuth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "qjCNaUp1xWSAl0ERyhubJhXXU"
consumerSecret <- "XewAdbX3cQnAR7ogNuh2hXFXrxOFb4g65RsBWdls1hDl2Kto4n"
my_oauth <- OAuthFactory$new(consumerKey = consumerKey, consumerSecret = consumerSecret, requestURL = requestURL, accessURL = accessURL, authURL = authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
save(my_oauth, file = "my_oauth.Rdata")
load("my_oauth.Rdata")
filterStream("thesis_tweets.json", track = c("islam","muslim","ISIS","terrorist","arab"), timeout = 100, oauth = my_oauth)
thesis_tweets.df <- parseTweets("thesis_tweets.json", simplify = TRUE)
c( length(grep("islam", tweets.df$text, ignore.case = TRUE)), length(grep("muslim", tweets.df$text, ignore.case = TRUE)),
length(grep("ISIS", tweets.df$text, ignore.case = TRUE)), length(grep("terrorist", tweets.df$text, ignore.case = TRUE)),
length(grep("arab", tweets.df$text, ignore.case = TRUE)))
c( length(grep("islam", thesis_tweets.df$text, ignore.case = TRUE)), length(grep("muslim", thesis_tweets.df$text, ignore.case = TRUE)),
length(grep("ISIS", thesis_tweets.df$text, ignore.case = TRUE)), length(grep("terrorist", thesis_tweets.df$text, ignore.case = TRUE)),
length(grep("arab", thesis_tweets.df$text, ignore.case = TRUE)))
View(thesis_tweets.df)
count.tweets(thesis_tweets.df)
library(smappR)
install.packages(smappR)
install.packages("smappR")
library(smappR)
install.packages("smappR")
library(twitteR)
library(ROAuth)
library(stringr)
library(wordcloud)
library(stringi)
library(data.table)
library(stringr)
library(tm)
library(stats)
library(ggplot2)
library(ggthemes)
library(reshape2)
library(igraph)
library(sna)
library(Matrix)
library(SparseM)
library(dplyr)
library(SnowballC)
library(scales)
library(psych)
library(ggrepel)
library(lsa)
library(gmodels)
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none') {
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence <- gsub("&amp", "", sentence)
sentence <- gsub("[^[:alnum:]///' ]", "", sentence)
sentence <- gsub('[[:punct:]]', '', sentence)
sentence <- gsub('[[:cntrl:]]', '', sentence)
sentence <- gsub('\\d+', '', sentence)
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df <- data.frame(score=scores)
return(scores.df)
}
pos.words <- scan('positive-words.txt', what='character', comment.char=';')
neg.words <- scan('negative-words.txt', what='character', comment.char=';')
setwd("~/Documents/2015-2016/Thesis/Analysis")
pos.words <- scan('positive-words.txt', what='character', comment.char=';')
neg.words <- scan('negative-words.txt', what='character', comment.char=';')
muslims <- read.csv("together_true_names_4_3_to_4_5.csv")
not_muslims <- read.csv("together_false_names_4_3_to_4_5.csv")
vars <- c("text","screen_name","clean_screen_name","name_check")
muslims <- muslims[vars]
not_muslims <- not_muslims[vars]
allvars <- c("text","screen_name","clean_screen_name","name_check", "retweet_name","rt_name_check")
all_tweets <- all_tweets[allvars]
muslims$text <- gsub("&amp", " ", muslims$text)
muslims$text <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", muslims$text)
muslims$text <- gsub("@\\w+", " ", muslims$text)
muslims$text <- gsub("[[:punct:]]", " ", muslims$text)
muslims$text <- gsub("[[:digit:]]", " ", muslims$text)
muslims$text <- gsub("http\\w+", " ", muslims$text)
muslims$text <- gsub("[ \t]{2,}", " ", muslims$text)
muslims$text <- gsub("^\\s+|\\s+$", " ", muslims$text)
not_muslims$text <- gsub("&amp", " ", not_muslims$text)
not_muslims$text <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", not_muslims$text)
not_muslims$text <- gsub("@\\w+", " ", not_muslims$text)
not_muslims$text <- gsub("[[:punct:]]", " ", not_muslims$text)
not_muslims$text <- gsub("[[:digit:]]", " ", not_muslims$text)
not_muslims$text <- gsub("http\\w+", " ", not_muslims$text)
not_muslims$text <- gsub("[ \t]{2,}", " ", not_muslims$text)
not_muslims$text <- gsub("^\\s+|\\s+$", " ", not_muslims$text)
non.muslims_text <- sapply(not_muslims$text, function(row) iconv(row, "latin1", "ASCII", sub=""))
non.muslimCorpus <- paste(unlist(non.muslims_text), collapse =" ") #to get all of the tweets together
non.muslimCorpus <- Corpus(VectorSource(non.muslimCorpus))
non.muslimCorpus <- tm_map(non.muslimCorpus, PlainTextDocument)
non.muslimCorpus <- tm_map(non.muslimCorpus, removePunctuation)
non.muslimCorpus <- tm_map(non.muslimCorpus, content_transformer(tolower),lazy=TRUE)
mystopwords <- c("islam","muslim")
non.muslimCorpus <- tm_map(non.muslimCorpus, removeWords, c(stopwords('english'),mystopwords))
noneut_not_muslims <- not_muslims[!not_muslims$score == "0", ]
noneut_non.muslims_text <- sapply(noneut_not_muslims$text, function(row) iconv(row, "latin1", "ASCII", sub=""))
noneut_non.muslimCorpus <- paste(unlist(noneut_non.muslims_text), collapse =" ") #to get all of the tweets together
noneut_non.muslimCorpus <- Corpus(VectorSource(noneut_non.muslimCorpus))
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, PlainTextDocument)
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, removePunctuation)
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, content_transformer(tolower),lazy=TRUE)
mystopwords <- c("islam","muslim")
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, removeWords, c(stopwords('english'),mystopwords))
noneut_non.muslim.dtm <- TermDocumentMatrix(noneut_non.muslimCorpus)
noneut_non.muslim.m <- as.matrix(noneut_non.muslim.dtm)
noneut_non.muslim.v <- sort(rowSums(noneut_non.muslim.m),decreasing=TRUE)
noneut_non.muslim.d <- data.frame(word = names(noneut_non.muslim.v),freq=noneut_non.muslim.v)
noneut_non.muslim.d$score <- score.sentiment(noneut_non.muslim.d$word, pos.words, neg.words, .progress="text")
library(twitteR)
library(ROAuth)
library(stringr)
library(wordcloud)
library(stringi)
library(data.table)
library(stringr)
library(tm)
library(stats)
library(ggplot2)
library(ggthemes)
library(reshape2)
library(igraph)
library(sna)
library(Matrix)
library(SparseM)
library(dplyr)
library(SnowballC)
library(scales)
library(psych)
library(ggrepel)
library(lsa)
library(gmodels)
noneut_non.muslim.d$score <- score.sentiment(noneut_non.muslim.d$word, pos.words, neg.words, .progress="text")
noneut_non.muslim.d$sentiment <- rep(0)
noneut_non.muslims_text <- sapply(noneut_not_muslims$text, function(row) iconv(row, "latin1", "ASCII", sub=""))
noneut_non.muslimCorpus <- paste(unlist(noneut_non.muslims_text), collapse =" ") #to get all of the tweets together
noneut_non.muslimCorpus <- Corpus(VectorSource(noneut_non.muslimCorpus))
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, PlainTextDocument)
noneut_not_muslims <- not_muslims[!not_muslims$score == "0", ]
not_muslims$score <- score.sentiment(not_muslims$text, pos.words, neg.words, .progress="text")
noneut_not_muslims <- not_muslims[!not_muslims$score == "0", ]
noneut_non.muslims_text <- sapply(noneut_not_muslims$text, function(row) iconv(row, "latin1", "ASCII", sub=""))
noneut_non.muslimCorpus <- paste(unlist(noneut_non.muslims_text), collapse =" ") #to get all of the tweets together
noneut_non.muslimCorpus <- Corpus(VectorSource(noneut_non.muslimCorpus))
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, PlainTextDocument)
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, removePunctuation)
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, content_transformer(tolower),lazy=TRUE)
mystopwords <- c("islam","muslim")
noneut_non.muslimCorpus <- tm_map(noneut_non.muslimCorpus, removeWords, c(stopwords('english'),mystopwords))
noneut_non.muslim.dtm <- TermDocumentMatrix(noneut_non.muslimCorpus)
noneut_non.muslim.m <- as.matrix(noneut_non.muslim.dtm)
noneut_non.muslim.v <- sort(rowSums(noneut_non.muslim.m),decreasing=TRUE)
noneut_non.muslim.d <- data.frame(word = names(noneut_non.muslim.v),freq=noneut_non.muslim.v)
noneut_non.muslim.d$score <- score.sentiment(noneut_non.muslim.d$word, pos.words, neg.words, .progress="text")
noneut_non.muslim.d$sentiment <- rep(0)
noneut_non.muslim.d$sentiment <- ifelse(noneut_non.muslim.d$score>=1, "Positive", noneut_non.muslim.d$sentiment)
noneut_non.muslim.d$sentiment <- ifelse(noneut_non.muslim.d$score==0, "Neutral", noneut_non.muslim.d$sentiment)
noneut_non.muslim.d$sentiment <- ifelse(noneut_non.muslim.d$score<=-1, "Negative", noneut_non.muslim.d$sentiment)
head(noneut_non.muslim.d, 51)
head(noneut_non.muslim.d, 50)
subset(noneut_non.muslim.d[1:50,])    %>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
write.csv(noneut_non.muslim.d, "Most_common_noneut_non.muslims.csv")
noneut_non.muslim.dtm <- TermDocumentMatrix(noneut_non.muslimCorpus)
noneut_non.muslim.m <- as.matrix(noneut_non.muslim.dtm)
noneut_non.muslim.v <- sort(rowSums(noneut_non.muslim.m),decreasing=TRUE)
noneut_non.muslim.d <- data.frame(word = names(noneut_non.muslim.v),freq=noneut_non.muslim.v)
write.csv(noneut_non.muslim.d, "Most_common_noneut_non.muslims.csv")
library(xtable)
table(noneut_muslims$raw_score==0)
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none') {
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence <- gsub("&amp", "", sentence)
sentence <- gsub("[^[:alnum:]///' ]", "", sentence)
sentence <- gsub('[[:punct:]]', '', sentence)
sentence <- gsub('[[:cntrl:]]', '', sentence)
sentence <- gsub('\\d+', '', sentence)
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df <- data.frame(score=scores)
return(scores.df)
}
describe(muslims$raw_score)
describe(not_muslims$raw_score)
library(twitteR)
library(ROAuth)
library(stringr)
library(wordcloud)
library(stringi)
library(data.table)
library(stringr)
library(tm)
library(stats)
library(ggplot2)
library(ggthemes)
library(reshape2)
library(igraph)
library(sna)
library(Matrix)
library(SparseM)
library(dplyr)
library(SnowballC)
library(scales)
library(psych)
library(ggrepel)
library(lsa)
library(gmodels)
library(xtable)
setwd("~/Documents/2015-2016/Thesis/Analysis/")
score.sentiment <- function(sentences, pos.words, neg.words, .progress='none') {
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence <- gsub("&amp", "", sentence)
sentence <- gsub("[^[:alnum:]///' ]", "", sentence)
sentence <- gsub('[[:punct:]]', '', sentence)
sentence <- gsub('[[:cntrl:]]', '', sentence)
sentence <- gsub('\\d+', '', sentence)
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df <- data.frame(score=scores)
return(scores.df)
}
pos.words <- scan('positive-words.txt', what='character', comment.char=';')
neg.words <- scan('negative-words.txt', what='character', comment.char=';')
muslims <- read.csv("together_true_names_4_3_to_4_5.csv")
not_muslims <- read.csv("together_false_names_4_3_to_4_5.csv")
all_tweets <- read.csv("together_names_4_3_to_4_5.csv")
vars <- c("text","screen_name","clean_screen_name","name_check")
muslims <- muslims[vars]
not_muslims <- not_muslims[vars]
allvars <- c("text","screen_name","clean_screen_name","name_check", "retweet_name","rt_name_check")
all_tweets <- all_tweets[allvars]
muslims$text <- gsub("&amp", " ", muslims$text)
muslims$text <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", muslims$text)
muslims$text <- gsub("@\\w+", " ", muslims$text)
muslims$text <- gsub("[[:punct:]]", " ", muslims$text)
muslims$text <- gsub("[[:digit:]]", " ", muslims$text)
muslims$text <- gsub("http\\w+", " ", muslims$text)
muslims$text <- gsub("[ \t]{2,}", " ", muslims$text)
muslims$text <- gsub("^\\s+|\\s+$", " ", muslims$text)
not_muslims$text <- gsub("&amp", " ", not_muslims$text)
not_muslims$text <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", not_muslims$text)
not_muslims$text <- gsub("@\\w+", " ", not_muslims$text)
not_muslims$text <- gsub("[[:punct:]]", " ", not_muslims$text)
not_muslims$text <- gsub("[[:digit:]]", " ", not_muslims$text)
not_muslims$text <- gsub("http\\w+", " ", not_muslims$text)
not_muslims$text <- gsub("[ \t]{2,}", " ", not_muslims$text)
not_muslims$text <- gsub("^\\s+|\\s+$", " ", not_muslims$text)
all_tweets$text <- gsub("&amp", " ", all_tweets$text)
all_tweets$text <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", " ", all_tweets$text)
all_tweets$text <- gsub("@\\w+", " ", all_tweets$text)
all_tweets$text <- gsub("[[:punct:]]", " ", all_tweets$text)
all_tweets$text <- gsub("[[:digit:]]", " ", all_tweets$text)
all_tweets$text <- gsub("http\\w+", " ", all_tweets$text)
all_tweets$text <- gsub("[ \t]{2,}", " ", all_tweets$text)
all_tweets$text <- gsub("^\\s+|\\s+$", " ", all_tweets$text)
muslims$score <- score.sentiment(muslims$text, pos.words, neg.words, .progress="text")
not_muslims$score <- score.sentiment(not_muslims$text, pos.words, neg.words, .progress="text")
all_tweets$score <- score.sentiment(all_tweets$text, pos.words, neg.words, .progress="text")
muslims$raw_score <- as.numeric(unlist(muslims$score))[1:nrow(muslims)]
not_muslims$raw_score <- as.numeric(unlist(not_muslims$score))[1:nrow(not_muslims)]
all_tweets$raw_score <- as.numeric(unlist(all_tweets$score))[1:nrow(all_tweets)]
library(stargazer)
describe(muslims$raw_score)
describe(not_muslims$raw_score)
describe(all_tweets$raw_score)
x1 <- describe(muslims$raw_score)
x2 <- describe(not_muslims$raw_score)
x3 <- describe(all_tweets$raw_score)
stargazer(x1, x2, x3)
xtable(x1, x2, x3)
xtable(x1, x2)
xtable(x1(, x2))
xtable(x1)
stargazer(attitude)
View(attitude)
x1 <- rep(0)
x1$muslims <- muslims$raw_score
x1$non_muslims <- not_muslims$raw_score
x1$all_tweets <- all_tweets$raw_score
head(x1)
stargazer(x1)
x1 <- data.frame(Muslims=numeric(),
Non-Muslims=numeric(),
All_Users=numeric(),
stringsAsFactors=FALSE)
x1 <- data.frame(Muslims=numeric(), Non-Muslims=numeric(), All_Users=numeric(), stringsAsFactors=FALSE)
x1 <- data.frame(Muslims=numeric(), Non-Muslims=numeric(), All_Users=numeric())
x1 <- data.frame(Muslims=integer(), Non-Muslims=integer(), All_Users=integer())
nodata <- data.frame(x= numeric(0), y= integer(0), z = character(0))
View(nodata)
nodata$x <- muslims$raw_score
x1 <- describe(muslims$raw_score)
stargazer(x1)
stargazer(x1, flip=TRUE)
describe(muslims$raw_score)
describe(not_muslims$raw_score)
describe(all_tweets$raw_score)
muslims$pos.neg <- cut(muslims$raw_score, breaks=c(-100,-0.1,0.1,100), label=c("Negative", "Neutral","Positive"))
muslimsposneg <- table(muslims$pos.neg)
prop.table(muslimsposneg) #IN PAPER
not_muslims$pos.neg <- cut(not_muslims$raw_score, breaks=c(-100,-0.1,0.1,100), label=c("Negative", "Neutral","Positive"))
not_muslimsposneg <- table(not_muslims$pos.neg)
prop.table(not_muslimsposneg) #IN PAPER
all_tweets$pos.neg <- cut(all_tweets$raw_score, breaks=c(-100,-0.1,0.1,100), label=c("Negative", "Neutral","Positive"))
alltweets_posneg <- table(all_tweets$pos.neg)
prop.table(alltweets_posneg) #IN PAPER
noneut_muslims <- muslims[!muslims$score == "0", ]
noneut_not_muslims <- not_muslims[!not_muslims$score == "0", ]
noneut_all_tweets <- all_tweets[!all_tweets$score == "0", ]
noneut_muslims$raw_score <- as.numeric(unlist(noneut_muslims$score))[1:nrow(noneut_muslims)]
noneut_not_muslims$raw_score <- as.numeric(unlist(noneut_not_muslims$score))[1:nrow(noneut_not_muslims)]
noneut_all_tweets$raw_score <- as.numeric(unlist(noneut_all_tweets$score))[1:nrow(noneut_all_tweets)]
t.test(muslims$raw_score, not_muslims$raw_score) #IN PAPER
test1 <- t.test(muslims$raw_score, not_muslims$raw_score) #IN PAPER
xtable(test1)
stargazer(test1)
View(muslims)
noneut_muslims <- muslims[!muslims$score == "0", ]
noneut_not_muslims <- not_muslims[!not_muslims$score == "0", ]
noneut_all_tweets <- all_tweets[!all_tweets$score == "0", ]
noneut_muslims$raw_score <- as.numeric(unlist(noneut_muslims$score))[1:nrow(noneut_muslims)]
noneut_not_muslims$raw_score <- as.numeric(unlist(noneut_not_muslims$score))[1:nrow(noneut_not_muslims)]
noneut_all_tweets$raw_score <- as.numeric(unlist(noneut_all_tweets$score))[1:nrow(noneut_all_tweets)]
table(noneut_muslims$raw_score==0)
table(noneut_muslims$raw_score<0)
muslims_text <- sapply(muslims$text, function(row) iconv(row, "latin1", "ASCII", sub=""))
muslimCorpus <- paste(unlist(muslims_text), collapse =" ") #to get all of the tweets together
muslimCorpus <- Corpus(VectorSource(muslimCorpus))
muslimCorpus <- tm_map(muslimCorpus, PlainTextDocument)
muslimCorpus <- tm_map(muslimCorpus, removePunctuation)
muslimCorpus <- tm_map(muslimCorpus, content_transformer(tolower),lazy=TRUE)
mystopwords <- c("islam","muslim")
muslimCorpus <- tm_map(muslimCorpus, removeWords, c(stopwords("english"),mystopwords))
muslim.dtm <- TermDocumentMatrix(muslimCorpus)
muslim.dtm
muslim.m <- as.matrix(muslim.dtm)
muslim.v <- sort(rowSums(muslim.m),decreasing=TRUE)
muslim.d <- data.frame(word = names(muslim.v),freq=muslim.v)
muslim.d$score <- score.sentiment(muslim.d$word, pos.words, neg.words, .progress="text")
muslim.d$sentiment <- rep(0)
muslim.d$sentiment <- ifelse(muslim.d$score>=1, "Positive", muslim.d$sentiment)
muslim.d$sentiment <- ifelse(muslim.d$score==0, "Neutral", muslim.d$sentiment)
muslim.d$sentiment <- ifelse(muslim.d$score<=-1, "Negative", muslim.d$sentiment)
head(muslim.d, 25)
subset(muslim.d[1:50,])    %>%
ggplot(aes(x=word, y=freq, fill=sentiment)) +
geom_bar(stat="identity", colour="white") +
theme(axis.text.x=element_text(angle=45, hjust=1)) + ylab("Frequency") + xlab("Word") +
scale_fill_manual(values=c("#990000", "#003399", "#339933"))
non.muslims_text <- sapply(not_muslims$text, function(row) iconv(row, "latin1", "ASCII", sub=""))
non.muslimCorpus <- paste(unlist(non.muslims_text), collapse =" ") #to get all of the tweets together
non.muslimCorpus <- Corpus(VectorSource(non.muslimCorpus))
non.muslimCorpus <- tm_map(non.muslimCorpus, PlainTextDocument)
non.muslimCorpus <- tm_map(non.muslimCorpus, removePunctuation)
non.muslimCorpus <- tm_map(non.muslimCorpus, content_transformer(tolower),lazy=TRUE)
mystopwords <- c("islam","muslim")
non.muslimCorpus <- tm_map(non.muslimCorpus, removeWords, c(stopwords('english'),mystopwords))
non.muslim.dtm <- TermDocumentMatrix(non.muslimCorpus)
non.muslim.m <- as.matrix(non.muslim.dtm)
non.muslim.v <- sort(rowSums(non.muslim.m),decreasing=TRUE)
non.muslim.d <- data.frame(word = names(non.muslim.v),freq=non.muslim.v)
non.muslim.d$score <- score.sentiment(non.muslim.d$word, pos.words, neg.words, .progress="text")
non.muslim.d$sentiment <- rep(0)
non.muslim.d$sentiment <- ifelse(non.muslim.d$score>=1, "Positive", non.muslim.d$sentiment)
non.muslim.d$sentiment <- ifelse(non.muslim.d$score==0, "Neutral", non.muslim.d$sentiment)
non.muslim.d$sentiment <- ifelse(non.muslim.d$score<=-1, "Negative", non.muslim.d$sentiment)
head(non.muslim.d, 25)
all.corpus <- c(muslimCorpus, non.muslimCorpus)
all.corpus <- Corpus(VectorSource(all.corpus))
all.tdm <- TermDocumentMatrix(all.corpus)
colnames(all.tdm) <- c("Muslims", "Non_Muslims")
all.m <- as.matrix(all.tdm)
all.m.trans <- t(all.m)
all.v <- sort(rowSums(all.m),decreasing=TRUE)
all.d <- data.frame(word = names(all.v), freq=all.v)
summing = function(x) x/sum(x, na.rm=T)
all.tdm_new = apply(all.tdm, 2, summing)
head(all.tdm_new) #relative frequencies
all.m_new <- as.matrix(all.tdm_new)
all.m_new_mus <- data.table(all.m_new, key="Muslims", keep.rownames=TRUE)
all.m_new_mus_m <- setorder(all.m_new_mus, -Muslims, -Non_Muslims)
all.m_new_mus_nm <- setorder(all.m_new_mus, -Non_Muslims, -Muslims)
corall <- cor(all.m) #correlations
corall
xtable(corall)
setwd("~/finalproject-p5-team1/data")
install.packages("RJSONIO")
library(RJSONIO)
professors <- fromJSON("professors.json")
rm(list=ls())
library(RJSONIO)
professors <- fromJSON("professors.json")
professors.m <- as.matrix(professors)
View(professors.m)
CS_profs <- fromJSON("CS_profs.json")
CS_profs <- unlist(as.matrix(CS_profs))
RMP <- read.csv("rateMyProfessor.csv")
View(RMP)
professors <- fromJSON("professors.json")
professors.m <- as.matrix(professors)
library(RJSONIO)
professors <- fromJSON("professors.json")
professors.m <- unlist(as.matrix(professors))
View(RMP)
professors.m <- matrix(unlist(professors), ncol=5, byrow=TRUE)
colnames(professors) <- c("first_name", "id", "last_name", "middle_name", "nugget")
professors <- fromJSON("professors.json")
colnames(professors) <- c("first_name", "id", "last_name", "middle_name", "nugget")
setwd("~/finalproject-p5-team1/data")
professors <- fromJSON("professors.json")
colnames(professors) <- c("first_name", "id", "last_name", "middle_name", "nugget")
setwd("~/finalproject-p5-team1/data")
professors <- fromJSON("professors.json")
professors <- matrix(unlist(professors), ncol = 5, byrow = TRUE)
colnames(professors) <- c("first_name", "id", "last_name", "middle_name", "nugget")
View(professors)
prof_reviews <- fromJSON("CS_profs.json")
prof_reviews <- matrix(unlist(prof_reviews), ncol = 6, byrow = TRUE)
colnames(prof_reviews) <- c("course_ids", "created", "id", "professor_ids", "review_text", "workload_text")
View(prof_reviews)
head(prof_reviews)
prof_reviews_df <- as.data.frame(prof_reviews)
View(prof_reviews_df)
View(prof_reviews_df)
View(prof_reviews)
prof_reviews <- fromJSON("CS_profs.json")
prof_reviews <- matrix(unlist(prof_reviews), ncol = 6, byrow = TRUE)
colnames(prof_reviews) <- c("course_ids", "created", "id", "professor_ids", "review_text", "workload_text")
View(prof_reviews)
head(prof_reviews)
View(prof_reviews)
professors <- fromJSON("professors.json")
professors <- matrix(unlist(professors), ncol = 5, byrow = TRUE)
colnames(professors) <- c("first_name", "id", "last_name", "middle_name", "nugget")
View(professors)
merged <- merge(prof_reviews,professors, by="id" )
View(merged)
professors <- fromJSON("professors.json")
professors <- matrix(unlist(professors), ncol = 5, byrow = TRUE)
colnames(professors) <- c("first_name", "id", "last_name", "middle_name", "nugget")
View(professors)
prof_reviews <- fromJSON("CS_profs.json")
prof_reviews <- matrix(unlist(prof_reviews), ncol = 6, byrow = TRUE)
colnames(prof_reviews) <- c("course_ids", "created", "id", "professor_ids", "review_text", "workload_text")
View(prof_reviews)
head(prof_reviews)
library(RJSONIO)
setwd("~/.Trash/finalproject-p5-team1")
setwd("~/finalproject-p5-team1")
load("data/prof_combined.RData")
View(prof_combined)
